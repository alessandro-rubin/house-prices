{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_log_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# House price regression using TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have to: \n",
    "\n",
    "1) load the data\n",
    "\n",
    "2) apply some basic feature engineering and cleaning\n",
    "\n",
    "3) encode and normalize the data into something that can be efficiently computed by tensorflow\n",
    "\n",
    "4) train the model, score it and compute metrics\n",
    "\n",
    "5) check the model predictions visually\n",
    "\n",
    "6) predict the house prices in the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fore more info:\n",
    "\n",
    "https://www.tensorflow.org/tutorials/load_data/pandas_dataframe\n",
    "\n",
    "https://www.tensorflow.org/tutorials/load_data/csv\n",
    "\n",
    "https://www.tensorflow.org/tutorials/structured_data/preprocessing_layers?authuser=2\n",
    "\n",
    "https://www.tensorflow.org/guide/keras/preprocessing_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from house_prices import feat_eng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_cat_f=['SaleCondition','ExterQual','Neighborhood','KitchenQual','SaleType','PoolQC','MSZoning']\n",
    "int_num_f=['OverallQual','LotArea','BsmtFinSF1','TotalBsmtSF','GrLivArea','GarageArea','YearBuilt','GarageCars','TotRmsAbvGrd','MSSubClass']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "label='SalePrice'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First implementation: only using numeric features and model.fit() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "      <th>TotFlrSF</th>\n",
       "      <th>nFlrs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "      <td>1710</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "      <td>1262</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "      <td>1786</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "      <td>1717</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "      <td>2198</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>1456</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>62.0</td>\n",
       "      <td>7917</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>175000</td>\n",
       "      <td>1647</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>1457</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>85.0</td>\n",
       "      <td>13175</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>210000</td>\n",
       "      <td>2073</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>1458</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>66.0</td>\n",
       "      <td>9042</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>GdPrv</td>\n",
       "      <td>Shed</td>\n",
       "      <td>2500</td>\n",
       "      <td>5</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>266500</td>\n",
       "      <td>2340</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>1459</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>9717</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>142125</td>\n",
       "      <td>1078</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>1460</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>75.0</td>\n",
       "      <td>9937</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>147500</td>\n",
       "      <td>1256</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1460 rows Ã— 83 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0        1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1        2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2        3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3        4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4        5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "...    ...         ...      ...          ...      ...    ...   ...      ...   \n",
       "1455  1456          60       RL         62.0     7917   Pave   NaN      Reg   \n",
       "1456  1457          20       RL         85.0    13175   Pave   NaN      Reg   \n",
       "1457  1458          70       RL         66.0     9042   Pave   NaN      Reg   \n",
       "1458  1459          20       RL         68.0     9717   Pave   NaN      Reg   \n",
       "1459  1460          20       RL         75.0     9937   Pave   NaN      Reg   \n",
       "\n",
       "     LandContour Utilities  ...  Fence MiscFeature MiscVal MoSold YrSold  \\\n",
       "0            Lvl    AllPub  ...    NaN         NaN       0      2   2008   \n",
       "1            Lvl    AllPub  ...    NaN         NaN       0      5   2007   \n",
       "2            Lvl    AllPub  ...    NaN         NaN       0      9   2008   \n",
       "3            Lvl    AllPub  ...    NaN         NaN       0      2   2006   \n",
       "4            Lvl    AllPub  ...    NaN         NaN       0     12   2008   \n",
       "...          ...       ...  ...    ...         ...     ...    ...    ...   \n",
       "1455         Lvl    AllPub  ...    NaN         NaN       0      8   2007   \n",
       "1456         Lvl    AllPub  ...  MnPrv         NaN       0      2   2010   \n",
       "1457         Lvl    AllPub  ...  GdPrv        Shed    2500      5   2010   \n",
       "1458         Lvl    AllPub  ...    NaN         NaN       0      4   2010   \n",
       "1459         Lvl    AllPub  ...    NaN         NaN       0      6   2008   \n",
       "\n",
       "     SaleType SaleCondition  SalePrice  TotFlrSF  nFlrs  \n",
       "0          WD        Normal     208500      1710    2.0  \n",
       "1          WD        Normal     181500      1262    1.0  \n",
       "2          WD        Normal     223500      1786    2.0  \n",
       "3          WD       Abnorml     140000      1717    2.0  \n",
       "4          WD        Normal     250000      2198    2.0  \n",
       "...       ...           ...        ...       ...    ...  \n",
       "1455       WD        Normal     175000      1647    2.0  \n",
       "1456       WD        Normal     210000      2073    1.0  \n",
       "1457       WD        Normal     266500      2340    2.0  \n",
       "1458       WD        Normal     142125      1078    1.0  \n",
       "1459       WD        Normal     147500      1256    1.0  \n",
       "\n",
       "[1460 rows x 83 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_eng(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_fraction=0.2\n",
    "x,y=train.drop(label,axis=1),train[label]\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=split_fraction, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_num_feat,test_num_feat=x_train[int_num_f],x_test[int_num_f]\n",
    "train_num_feat=tf.convert_to_tensor(train_num_feat)\n",
    "test_num_feat=tf.convert_to_tensor(test_num_feat)\n",
    "y_test=tf.convert_to_tensor(y_test)\n",
    "y_train=tf.convert_to_tensor(y_train)\n",
    "\n",
    "\n",
    "normalizer = tf.keras.layers.Normalization(axis=-1)\n",
    "normalizer.adapt(train_num_feat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1168, 10), dtype=int64, numpy=\n",
       "array([[    9, 11694,    48, ...,     3,     9,    20],\n",
       "       [    5,  6600,     0, ...,     1,     5,    20],\n",
       "       [    5, 13360,   713, ...,     2,     5,    30],\n",
       "       ...,\n",
       "       [    6,  8930,     0, ...,     2,     8,    90],\n",
       "       [    7,  3196,     0, ...,     2,     7,   120],\n",
       "       [    7, 16770,     0, ...,     2,     7,    60]], dtype=int64)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_num_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_basic_model():\n",
    "    model = tf.keras.Sequential([\n",
    "        normalizer,\n",
    "        tf.keras.layers.Dense(100, activation='relu'),\n",
    "        tf.keras.layers.Dropout(.25),\n",
    "        tf.keras.layers.Dense(100, activation='relu'),\n",
    "        tf.keras.layers.Dropout(.25),\n",
    "        tf.keras.layers.Dense(100, activation='relu'),\n",
    "        tf.keras.layers.Dense(1)\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss=tf.keras.losses.MeanSquaredError(),\n",
    "                  metrics=[tf.keras.metrics.RootMeanSquaredError(),tf.keras.metrics.MeanSquaredLogarithmicError()])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "78/78 [==============================] - 1s 11ms/step - loss: 38826831872.0000 - root_mean_squared_error: 197045.2500 - mean_squared_logarithmic_error: 86.2321 - val_loss: 39684472832.0000 - val_root_mean_squared_error: 199209.6250 - val_mean_squared_logarithmic_error: 42.6276\n",
      "Epoch 2/10\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 37870505984.0000 - root_mean_squared_error: 194603.4531 - mean_squared_logarithmic_error: 24.1735 - val_loss: 36649984000.0000 - val_root_mean_squared_error: 191441.8594 - val_mean_squared_logarithmic_error: 11.3346\n",
      "Epoch 3/10\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 29962022912.0000 - root_mean_squared_error: 173095.4219 - mean_squared_logarithmic_error: 6.0125 - val_loss: 21749278720.0000 - val_root_mean_squared_error: 147476.3594 - val_mean_squared_logarithmic_error: 2.4126\n",
      "Epoch 4/10\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 12535412736.0000 - root_mean_squared_error: 111961.6562 - mean_squared_logarithmic_error: 1.2092 - val_loss: 10206597120.0000 - val_root_mean_squared_error: 101027.7031 - val_mean_squared_logarithmic_error: 0.4673\n",
      "Epoch 5/10\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 5683224064.0000 - root_mean_squared_error: 75387.1641 - mean_squared_logarithmic_error: 0.3420 - val_loss: 9083967488.0000 - val_root_mean_squared_error: 95309.8516 - val_mean_squared_logarithmic_error: 0.2571\n",
      "Epoch 6/10\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 4814128128.0000 - root_mean_squared_error: 69383.9219 - mean_squared_logarithmic_error: 0.2332 - val_loss: 7528176128.0000 - val_root_mean_squared_error: 86765.0625 - val_mean_squared_logarithmic_error: 0.2031\n",
      "Epoch 7/10\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 4158922240.0000 - root_mean_squared_error: 64489.7070 - mean_squared_logarithmic_error: 0.1924 - val_loss: 6619381248.0000 - val_root_mean_squared_error: 81359.5859 - val_mean_squared_logarithmic_error: 0.1631\n",
      "Epoch 8/10\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 3290764288.0000 - root_mean_squared_error: 57365.1836 - mean_squared_logarithmic_error: 0.1478 - val_loss: 6016115200.0000 - val_root_mean_squared_error: 77563.6172 - val_mean_squared_logarithmic_error: 0.1339\n",
      "Epoch 9/10\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 2905337344.0000 - root_mean_squared_error: 53901.1797 - mean_squared_logarithmic_error: 0.1272 - val_loss: 5559132672.0000 - val_root_mean_squared_error: 74559.5938 - val_mean_squared_logarithmic_error: 0.1111\n",
      "Epoch 10/10\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 2554377984.0000 - root_mean_squared_error: 50540.8555 - mean_squared_logarithmic_error: 0.1096 - val_loss: 5014059008.0000 - val_root_mean_squared_error: 70810.0234 - val_mean_squared_logarithmic_error: 0.0961\n"
     ]
    }
   ],
   "source": [
    "model= get_basic_model()\n",
    "history=model.fit(train_num_feat, y_train, epochs=10, batch_size=15,validation_data=(test_num_feat,y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Excercise 2: preprocess by using keras functional API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Build the preprocessing model, passing data as dict\n",
    "\n",
    "2) numerical features should be normalized\n",
    "\n",
    "3) categorical features should be one hot encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SaleCondition', 'ExterQual', 'Neighborhood', 'KitchenQual', 'SaleType', 'PoolQC', 'MSZoning'] ['OverallQual', 'LotArea', 'BsmtFinSF1', 'TotalBsmtSF', 'GrLivArea', 'GarageArea', 'YearBuilt', 'GarageCars', 'TotRmsAbvGrd', 'MSSubClass']\n"
     ]
    }
   ],
   "source": [
    "print(int_cat_f,int_num_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'OverallQual': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'OverallQual')>,\n",
       " 'LotArea': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'LotArea')>,\n",
       " 'BsmtFinSF1': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'BsmtFinSF1')>,\n",
       " 'TotalBsmtSF': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'TotalBsmtSF')>,\n",
       " 'GrLivArea': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'GrLivArea')>,\n",
       " 'GarageArea': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'GarageArea')>,\n",
       " 'YearBuilt': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'YearBuilt')>,\n",
       " 'GarageCars': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'GarageCars')>,\n",
       " 'TotRmsAbvGrd': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'TotRmsAbvGrd')>,\n",
       " 'MSSubClass': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'MSSubClass')>,\n",
       " 'SaleCondition': <KerasTensor: shape=(None, 1) dtype=string (created by layer 'SaleCondition')>,\n",
       " 'ExterQual': <KerasTensor: shape=(None, 1) dtype=string (created by layer 'ExterQual')>,\n",
       " 'Neighborhood': <KerasTensor: shape=(None, 1) dtype=string (created by layer 'Neighborhood')>,\n",
       " 'KitchenQual': <KerasTensor: shape=(None, 1) dtype=string (created by layer 'KitchenQual')>,\n",
       " 'SaleType': <KerasTensor: shape=(None, 1) dtype=string (created by layer 'SaleType')>,\n",
       " 'PoolQC': <KerasTensor: shape=(None, 1) dtype=string (created by layer 'PoolQC')>,\n",
       " 'MSZoning': <KerasTensor: shape=(None, 1) dtype=string (created by layer 'MSZoning')>}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = {}\n",
    "for name in int_num_f+int_cat_f:\n",
    "    if name in int_num_f:\n",
    "        dtype = tf.float32\n",
    "    if (name in int_cat_f):\n",
    "        dtype = tf.string\n",
    "    inputs[name] = tf.keras.Input(shape=(1,), name=name, dtype=dtype)\n",
    "inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Numeric inputs:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenate the numeric input layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 10) dtype=float32 (created by layer 'normalization_2')>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_inputs = {name:input for name,input in inputs.items()\n",
    "                  if input.dtype==tf.float32}\n",
    "\n",
    "x = layers.Concatenate()(list(numeric_inputs.values()))\n",
    "norm = layers.Normalization()\n",
    "norm.adapt(np.array(train[numeric_inputs.keys()]))\n",
    "all_numeric_inputs = norm(x)\n",
    "\n",
    "all_numeric_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_inputs = [all_numeric_inputs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categorical inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, input in inputs.items():\n",
    "    if input.dtype == tf.float32:\n",
    "        continue\n",
    "  \n",
    "    lookup = layers.StringLookup(vocabulary=np.unique(train[name]))\n",
    "    one_hot = layers.CategoryEncoding(num_tokens=lookup.vocabulary_size())\n",
    "\n",
    "    x = lookup(input)\n",
    "    x = one_hot(x)\n",
    "    preprocessed_inputs.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<KerasTensor: shape=(None, 10) dtype=float32 (created by layer 'normalization_2')>,\n",
       " <KerasTensor: shape=(None, 7) dtype=float32 (created by layer 'category_encoding')>,\n",
       " <KerasTensor: shape=(None, 5) dtype=float32 (created by layer 'category_encoding_1')>,\n",
       " <KerasTensor: shape=(None, 26) dtype=float32 (created by layer 'category_encoding_2')>,\n",
       " <KerasTensor: shape=(None, 5) dtype=float32 (created by layer 'category_encoding_3')>,\n",
       " <KerasTensor: shape=(None, 10) dtype=float32 (created by layer 'category_encoding_4')>,\n",
       " <KerasTensor: shape=(None, 5) dtype=float32 (created by layer 'category_encoding_5')>,\n",
       " <KerasTensor: shape=(None, 6) dtype=float32 (created by layer 'category_encoding_6')>]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the preprocessing layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_inputs_cat = layers.Concatenate()(preprocessed_inputs)\n",
    "\n",
    "house_prices_preprocessing = tf.keras.Model(inputs, preprocessed_inputs_cat)\n",
    "\n",
    "#tf.keras.utils.plot_model(model = house_prices_preprocessing , rankdir=\"LR\", dpi=72, show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(preprocessing_head, inputs:dict):\n",
    "    preprocessed_inputs = preprocessing_head(inputs)\n",
    "    x=tf.keras.layers.Dense(100,activation='relu')(preprocessed_inputs)\n",
    "    x=tf.keras.layers.Dropout(0.25)(x)\n",
    "    x=tf.keras.layers.Dense(150,activation='relu')(x)\n",
    "    x=tf.keras.layers.Dropout(0.25)(x)\n",
    "    x=tf.keras.layers.Dense(100,activation='relu')(x)\n",
    "    result = tf.keras.layers.Dense(1)(x)\n",
    "    model = tf.keras.Model(inputs, result)\n",
    "    model.compile(optimizer='adam',\n",
    "                loss=tf.keras.losses.MeanSquaredLogarithmicError(),\n",
    "                metrics=[tf.keras.metrics.RootMeanSquaredError(),tf.keras.metrics.MeanSquaredLogarithmicError()])\n",
    "    return model\n",
    "\n",
    "house_price_model = create_model(house_prices_preprocessing, inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " BsmtFinSF1 (InputLayer)        [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " ExterQual (InputLayer)         [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " GarageArea (InputLayer)        [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " GarageCars (InputLayer)        [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " GrLivArea (InputLayer)         [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " KitchenQual (InputLayer)       [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " LotArea (InputLayer)           [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " MSSubClass (InputLayer)        [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " MSZoning (InputLayer)          [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " Neighborhood (InputLayer)      [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " OverallQual (InputLayer)       [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " PoolQC (InputLayer)            [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " SaleCondition (InputLayer)     [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " SaleType (InputLayer)          [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " TotRmsAbvGrd (InputLayer)      [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " TotalBsmtSF (InputLayer)       [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " YearBuilt (InputLayer)         [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " model (Functional)             (None, 74)           21          ['BsmtFinSF1[0][0]',             \n",
      "                                                                  'ExterQual[0][0]',              \n",
      "                                                                  'GarageArea[0][0]',             \n",
      "                                                                  'GarageCars[0][0]',             \n",
      "                                                                  'GrLivArea[0][0]',              \n",
      "                                                                  'KitchenQual[0][0]',            \n",
      "                                                                  'LotArea[0][0]',                \n",
      "                                                                  'MSSubClass[0][0]',             \n",
      "                                                                  'MSZoning[0][0]',               \n",
      "                                                                  'Neighborhood[0][0]',           \n",
      "                                                                  'OverallQual[0][0]',            \n",
      "                                                                  'PoolQC[0][0]',                 \n",
      "                                                                  'SaleCondition[0][0]',          \n",
      "                                                                  'SaleType[0][0]',               \n",
      "                                                                  'TotRmsAbvGrd[0][0]',           \n",
      "                                                                  'TotalBsmtSF[0][0]',            \n",
      "                                                                  'YearBuilt[0][0]']              \n",
      "                                                                                                  \n",
      " dense_8 (Dense)                (None, 100)          7500        ['model[0][0]']                  \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)            (None, 100)          0           ['dense_8[0][0]']                \n",
      "                                                                                                  \n",
      " dense_9 (Dense)                (None, 150)          15150       ['dropout_4[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)            (None, 150)          0           ['dense_9[0][0]']                \n",
      "                                                                                                  \n",
      " dense_10 (Dense)               (None, 100)          15100       ['dropout_5[0][0]']              \n",
      "                                                                                                  \n",
      " dense_11 (Dense)               (None, 1)            101         ['dense_10[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 37,872\n",
      "Trainable params: 37,851\n",
      "Non-trainable params: 21\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(house_price_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to create train and validation dictionaries\n",
    "def train_val(df,val_fraction,shuffle=False):\n",
    "    '''returns the train and validation sets as dictionaries'''\n",
    "    if shuffle=True:\n",
    "        df=df.sample(1)\n",
    "\n",
    "    return train_dict,train_label,val_dict,Val_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features_dict={name:np.array(train[name]) for name in (int_num_f+int_cat_f)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Normal', 'Normal', 'Normal', ..., 'Normal', 'Normal', 'Normal'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features_dict['SaleCondition']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1460, 74), dtype=float32, numpy=\n",
       "array([[ 0.65147984, -0.20714168,  0.57542485, ...,  0.        ,\n",
       "         1.        ,  0.        ],\n",
       "       [-0.0718355 , -0.09188636,  1.1719922 , ...,  0.        ,\n",
       "         1.        ,  0.        ],\n",
       "       [ 0.65147984,  0.07347997,  0.09290722, ...,  0.        ,\n",
       "         1.        ,  0.        ],\n",
       "       ...,\n",
       "       [ 0.65147984, -0.14781025, -0.36987108, ...,  0.        ,\n",
       "         1.        ,  0.        ],\n",
       "       [-0.7951509 , -0.08016039, -0.8655483 , ...,  0.        ,\n",
       "         1.        ,  0.        ],\n",
       "       [-0.7951509 , -0.05811154,  0.8473894 , ...,  0.        ,\n",
       "         1.        ,  0.        ]], dtype=float32)>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "house_prices_preprocessing(train_features_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "78/78 [==============================] - 3s 26ms/step - loss: 85.1055 - root_mean_squared_error: 196990.0781 - mean_squared_logarithmic_error: 85.1055 - val_loss: 50.3916 - val_root_mean_squared_error: 199666.2969 - val_mean_squared_logarithmic_error: 50.3916\n",
      "Epoch 2/100\n",
      "78/78 [==============================] - 1s 19ms/step - loss: 37.7070 - root_mean_squared_error: 196634.7656 - mean_squared_logarithmic_error: 37.7070 - val_loss: 28.2694 - val_root_mean_squared_error: 199023.4219 - val_mean_squared_logarithmic_error: 28.2694\n",
      "Epoch 3/100\n",
      "78/78 [==============================] - 1s 19ms/step - loss: 22.7486 - root_mean_squared_error: 195610.8750 - mean_squared_logarithmic_error: 22.7486 - val_loss: 18.1324 - val_root_mean_squared_error: 197563.4219 - val_mean_squared_logarithmic_error: 18.1324\n",
      "Epoch 4/100\n",
      "78/78 [==============================] - 1s 19ms/step - loss: 15.0963 - root_mean_squared_error: 193698.0625 - mean_squared_logarithmic_error: 15.0963 - val_loss: 12.4101 - val_root_mean_squared_error: 195122.4688 - val_mean_squared_logarithmic_error: 12.4101\n",
      "Epoch 5/100\n",
      "78/78 [==============================] - 1s 19ms/step - loss: 10.5520 - root_mean_squared_error: 190773.0781 - mean_squared_logarithmic_error: 10.5520 - val_loss: 8.8519 - val_root_mean_squared_error: 191696.7344 - val_mean_squared_logarithmic_error: 8.8519\n",
      "Epoch 6/100\n",
      "78/78 [==============================] - 1s 19ms/step - loss: 7.6690 - root_mean_squared_error: 186959.2500 - mean_squared_logarithmic_error: 7.6690 - val_loss: 6.4976 - val_root_mean_squared_error: 187360.0312 - val_mean_squared_logarithmic_error: 6.4976\n",
      "Epoch 7/100\n",
      "78/78 [==============================] - 1s 18ms/step - loss: 5.6819 - root_mean_squared_error: 182230.3906 - mean_squared_logarithmic_error: 5.6819 - val_loss: 4.8853 - val_root_mean_squared_error: 182300.7969 - val_mean_squared_logarithmic_error: 4.8853\n",
      "Epoch 8/100\n",
      "78/78 [==============================] - 1s 18ms/step - loss: 4.3043 - root_mean_squared_error: 176837.4531 - mean_squared_logarithmic_error: 4.3043 - val_loss: 3.7331 - val_root_mean_squared_error: 176627.6875 - val_mean_squared_logarithmic_error: 3.7331\n",
      "Epoch 9/100\n",
      "78/78 [==============================] - 1s 19ms/step - loss: 3.3423 - root_mean_squared_error: 171152.9531 - mean_squared_logarithmic_error: 3.3423 - val_loss: 2.8805 - val_root_mean_squared_error: 170416.8750 - val_mean_squared_logarithmic_error: 2.8805\n",
      "Epoch 10/100\n",
      "78/78 [==============================] - 1s 19ms/step - loss: 2.5779 - root_mean_squared_error: 164562.9844 - mean_squared_logarithmic_error: 2.5779 - val_loss: 2.2402 - val_root_mean_squared_error: 163818.8750 - val_mean_squared_logarithmic_error: 2.2402\n",
      "Epoch 11/100\n",
      "78/78 [==============================] - 1s 19ms/step - loss: 2.0160 - root_mean_squared_error: 157741.9062 - mean_squared_logarithmic_error: 2.0160 - val_loss: 1.7500 - val_root_mean_squared_error: 156886.0625 - val_mean_squared_logarithmic_error: 1.7500\n",
      "Epoch 12/100\n",
      "78/78 [==============================] - 1s 19ms/step - loss: 1.5866 - root_mean_squared_error: 150915.9844 - mean_squared_logarithmic_error: 1.5866 - val_loss: 1.3690 - val_root_mean_squared_error: 149655.1250 - val_mean_squared_logarithmic_error: 1.3690\n",
      "Epoch 13/100\n",
      "78/78 [==============================] - 1s 19ms/step - loss: 1.2503 - root_mean_squared_error: 143619.6562 - mean_squared_logarithmic_error: 1.2503 - val_loss: 1.0711 - val_root_mean_squared_error: 142254.8438 - val_mean_squared_logarithmic_error: 1.0711\n",
      "Epoch 14/100\n",
      "78/78 [==============================] - 1s 19ms/step - loss: 0.9691 - root_mean_squared_error: 135641.9375 - mean_squared_logarithmic_error: 0.9691 - val_loss: 0.8355 - val_root_mean_squared_error: 134683.8750 - val_mean_squared_logarithmic_error: 0.8355\n",
      "Epoch 15/100\n",
      "78/78 [==============================] - 1s 19ms/step - loss: 0.7699 - root_mean_squared_error: 128536.2188 - mean_squared_logarithmic_error: 0.7699 - val_loss: 0.6507 - val_root_mean_squared_error: 127083.8984 - val_mean_squared_logarithmic_error: 0.6507\n",
      "Epoch 16/100\n",
      "78/78 [==============================] - 1s 18ms/step - loss: 0.6028 - root_mean_squared_error: 120993.3516 - mean_squared_logarithmic_error: 0.6028 - val_loss: 0.5079 - val_root_mean_squared_error: 119660.5000 - val_mean_squared_logarithmic_error: 0.5079\n",
      "Epoch 17/100\n",
      "78/78 [==============================] - 1s 18ms/step - loss: 0.4746 - root_mean_squared_error: 113673.1016 - mean_squared_logarithmic_error: 0.4746 - val_loss: 0.3963 - val_root_mean_squared_error: 112371.3750 - val_mean_squared_logarithmic_error: 0.3963\n",
      "Epoch 18/100\n",
      "78/78 [==============================] - 1s 18ms/step - loss: 0.3782 - root_mean_squared_error: 106799.0078 - mean_squared_logarithmic_error: 0.3782 - val_loss: 0.3120 - val_root_mean_squared_error: 105572.5703 - val_mean_squared_logarithmic_error: 0.3120\n",
      "Epoch 19/100\n",
      "78/78 [==============================] - 1s 18ms/step - loss: 0.2997 - root_mean_squared_error: 100030.1797 - mean_squared_logarithmic_error: 0.2997 - val_loss: 0.2481 - val_root_mean_squared_error: 99247.7969 - val_mean_squared_logarithmic_error: 0.2481\n",
      "Epoch 20/100\n",
      "78/78 [==============================] - 1s 18ms/step - loss: 0.2481 - root_mean_squared_error: 94540.8438 - mean_squared_logarithmic_error: 0.2481 - val_loss: 0.1984 - val_root_mean_squared_error: 93259.6641 - val_mean_squared_logarithmic_error: 0.1984\n",
      "Epoch 21/100\n",
      "78/78 [==============================] - 1s 19ms/step - loss: 0.2003 - root_mean_squared_error: 88544.9375 - mean_squared_logarithmic_error: 0.2003 - val_loss: 0.1618 - val_root_mean_squared_error: 87950.7031 - val_mean_squared_logarithmic_error: 0.1618\n",
      "Epoch 22/100\n",
      "78/78 [==============================] - 1s 19ms/step - loss: 0.1654 - root_mean_squared_error: 83108.1094 - mean_squared_logarithmic_error: 0.1654 - val_loss: 0.1341 - val_root_mean_squared_error: 83153.5781 - val_mean_squared_logarithmic_error: 0.1341\n",
      "Epoch 23/100\n",
      "78/78 [==============================] - 1s 19ms/step - loss: 0.1389 - root_mean_squared_error: 78703.8984 - mean_squared_logarithmic_error: 0.1389 - val_loss: 0.1134 - val_root_mean_squared_error: 78935.9453 - val_mean_squared_logarithmic_error: 0.1134\n",
      "Epoch 24/100\n",
      "78/78 [==============================] - 1s 19ms/step - loss: 0.1255 - root_mean_squared_error: 75992.9844 - mean_squared_logarithmic_error: 0.1255 - val_loss: 0.0969 - val_root_mean_squared_error: 75034.8516 - val_mean_squared_logarithmic_error: 0.0969\n",
      "Epoch 25/100\n",
      "78/78 [==============================] - 2s 23ms/step - loss: 0.1107 - root_mean_squared_error: 72328.2422 - mean_squared_logarithmic_error: 0.1107 - val_loss: 0.0844 - val_root_mean_squared_error: 71606.4766 - val_mean_squared_logarithmic_error: 0.0844\n",
      "Epoch 26/100\n",
      "78/78 [==============================] - 2s 20ms/step - loss: 0.0935 - root_mean_squared_error: 67732.1484 - mean_squared_logarithmic_error: 0.0935 - val_loss: 0.0750 - val_root_mean_squared_error: 68640.3047 - val_mean_squared_logarithmic_error: 0.0750\n",
      "Epoch 27/100\n",
      "78/78 [==============================] - 2s 22ms/step - loss: 0.0919 - root_mean_squared_error: 66606.0547 - mean_squared_logarithmic_error: 0.0919 - val_loss: 0.0677 - val_root_mean_squared_error: 66052.5312 - val_mean_squared_logarithmic_error: 0.0677\n",
      "Epoch 28/100\n",
      "78/78 [==============================] - 2s 21ms/step - loss: 0.0813 - root_mean_squared_error: 63679.4570 - mean_squared_logarithmic_error: 0.0813 - val_loss: 0.0618 - val_root_mean_squared_error: 63751.2227 - val_mean_squared_logarithmic_error: 0.0618\n",
      "Epoch 29/100\n",
      "78/78 [==============================] - 2s 21ms/step - loss: 0.0736 - root_mean_squared_error: 60461.3359 - mean_squared_logarithmic_error: 0.0736 - val_loss: 0.0572 - val_root_mean_squared_error: 61794.2852 - val_mean_squared_logarithmic_error: 0.0572\n",
      "Epoch 30/100\n",
      "78/78 [==============================] - 2s 21ms/step - loss: 0.0718 - root_mean_squared_error: 60221.7578 - mean_squared_logarithmic_error: 0.0718 - val_loss: 0.0536 - val_root_mean_squared_error: 60073.0430 - val_mean_squared_logarithmic_error: 0.0536\n",
      "Epoch 31/100\n",
      "78/78 [==============================] - 2s 20ms/step - loss: 0.0666 - root_mean_squared_error: 57572.6367 - mean_squared_logarithmic_error: 0.0666 - val_loss: 0.0506 - val_root_mean_squared_error: 58600.4414 - val_mean_squared_logarithmic_error: 0.0506\n",
      "Epoch 32/100\n",
      "78/78 [==============================] - 2s 20ms/step - loss: 0.0656 - root_mean_squared_error: 56845.4062 - mean_squared_logarithmic_error: 0.0656 - val_loss: 0.0481 - val_root_mean_squared_error: 57230.2422 - val_mean_squared_logarithmic_error: 0.0481\n",
      "Epoch 33/100\n",
      "78/78 [==============================] - 2s 20ms/step - loss: 0.0583 - root_mean_squared_error: 53944.0938 - mean_squared_logarithmic_error: 0.0583 - val_loss: 0.0463 - val_root_mean_squared_error: 56196.5781 - val_mean_squared_logarithmic_error: 0.0463\n",
      "Epoch 34/100\n",
      "78/78 [==============================] - 2s 20ms/step - loss: 0.0583 - root_mean_squared_error: 52301.4688 - mean_squared_logarithmic_error: 0.0583 - val_loss: 0.0447 - val_root_mean_squared_error: 55278.8281 - val_mean_squared_logarithmic_error: 0.0447\n",
      "Epoch 35/100\n",
      "78/78 [==============================] - 2s 20ms/step - loss: 0.0573 - root_mean_squared_error: 53046.9297 - mean_squared_logarithmic_error: 0.0573 - val_loss: 0.0434 - val_root_mean_squared_error: 54453.5039 - val_mean_squared_logarithmic_error: 0.0434\n",
      "Epoch 36/100\n",
      "78/78 [==============================] - 2s 20ms/step - loss: 0.0544 - root_mean_squared_error: 52038.7305 - mean_squared_logarithmic_error: 0.0544 - val_loss: 0.0422 - val_root_mean_squared_error: 53639.5586 - val_mean_squared_logarithmic_error: 0.0422\n",
      "Epoch 37/100\n",
      "78/78 [==============================] - 2s 20ms/step - loss: 0.0530 - root_mean_squared_error: 51238.8398 - mean_squared_logarithmic_error: 0.0530 - val_loss: 0.0413 - val_root_mean_squared_error: 53063.7188 - val_mean_squared_logarithmic_error: 0.0413\n",
      "Epoch 38/100\n",
      "78/78 [==============================] - 2s 20ms/step - loss: 0.0492 - root_mean_squared_error: 49227.8203 - mean_squared_logarithmic_error: 0.0492 - val_loss: 0.0406 - val_root_mean_squared_error: 52594.4180 - val_mean_squared_logarithmic_error: 0.0406\n",
      "Epoch 39/100\n",
      "78/78 [==============================] - 2s 20ms/step - loss: 0.0492 - root_mean_squared_error: 48245.4609 - mean_squared_logarithmic_error: 0.0492 - val_loss: 0.0399 - val_root_mean_squared_error: 52096.0586 - val_mean_squared_logarithmic_error: 0.0399\n",
      "Epoch 40/100\n",
      "78/78 [==============================] - 2s 23ms/step - loss: 0.0491 - root_mean_squared_error: 48055.8477 - mean_squared_logarithmic_error: 0.0491 - val_loss: 0.0394 - val_root_mean_squared_error: 51726.6328 - val_mean_squared_logarithmic_error: 0.0394\n",
      "Epoch 41/100\n",
      "78/78 [==============================] - 2s 21ms/step - loss: 0.0497 - root_mean_squared_error: 48670.0078 - mean_squared_logarithmic_error: 0.0497 - val_loss: 0.0389 - val_root_mean_squared_error: 51346.8242 - val_mean_squared_logarithmic_error: 0.0389\n",
      "Epoch 42/100\n",
      "78/78 [==============================] - 2s 20ms/step - loss: 0.0489 - root_mean_squared_error: 48023.3945 - mean_squared_logarithmic_error: 0.0489 - val_loss: 0.0384 - val_root_mean_squared_error: 51077.0156 - val_mean_squared_logarithmic_error: 0.0384\n",
      "Epoch 43/100\n",
      "78/78 [==============================] - 2s 20ms/step - loss: 0.0492 - root_mean_squared_error: 45870.4531 - mean_squared_logarithmic_error: 0.0492 - val_loss: 0.0380 - val_root_mean_squared_error: 50800.1758 - val_mean_squared_logarithmic_error: 0.0380\n",
      "Epoch 44/100\n",
      "78/78 [==============================] - 2s 20ms/step - loss: 0.0459 - root_mean_squared_error: 46664.6406 - mean_squared_logarithmic_error: 0.0459 - val_loss: 0.0376 - val_root_mean_squared_error: 50527.5469 - val_mean_squared_logarithmic_error: 0.0376\n",
      "Epoch 45/100\n",
      "78/78 [==============================] - 2s 20ms/step - loss: 0.0461 - root_mean_squared_error: 46596.0547 - mean_squared_logarithmic_error: 0.0461 - val_loss: 0.0373 - val_root_mean_squared_error: 50286.3828 - val_mean_squared_logarithmic_error: 0.0373\n",
      "Epoch 46/100\n",
      "78/78 [==============================] - 2s 20ms/step - loss: 0.0487 - root_mean_squared_error: 46958.6719 - mean_squared_logarithmic_error: 0.0487 - val_loss: 0.0370 - val_root_mean_squared_error: 50072.2891 - val_mean_squared_logarithmic_error: 0.0370\n",
      "Epoch 47/100\n",
      "78/78 [==============================] - 2s 20ms/step - loss: 0.0460 - root_mean_squared_error: 44855.5781 - mean_squared_logarithmic_error: 0.0460 - val_loss: 0.0366 - val_root_mean_squared_error: 49879.3125 - val_mean_squared_logarithmic_error: 0.0366\n",
      "Epoch 48/100\n",
      "78/78 [==============================] - 2s 20ms/step - loss: 0.0444 - root_mean_squared_error: 45777.8125 - mean_squared_logarithmic_error: 0.0444 - val_loss: 0.0363 - val_root_mean_squared_error: 49681.3750 - val_mean_squared_logarithmic_error: 0.0363\n",
      "Epoch 49/100\n",
      "78/78 [==============================] - 2s 20ms/step - loss: 0.0463 - root_mean_squared_error: 46688.7227 - mean_squared_logarithmic_error: 0.0463 - val_loss: 0.0360 - val_root_mean_squared_error: 49516.2109 - val_mean_squared_logarithmic_error: 0.0360\n",
      "Epoch 50/100\n",
      "78/78 [==============================] - 2s 21ms/step - loss: 0.0411 - root_mean_squared_error: 43012.8828 - mean_squared_logarithmic_error: 0.0411 - val_loss: 0.0357 - val_root_mean_squared_error: 49384.4219 - val_mean_squared_logarithmic_error: 0.0357\n",
      "Epoch 51/100\n",
      "78/78 [==============================] - 2s 20ms/step - loss: 0.0435 - root_mean_squared_error: 44724.0859 - mean_squared_logarithmic_error: 0.0435 - val_loss: 0.0354 - val_root_mean_squared_error: 49261.2070 - val_mean_squared_logarithmic_error: 0.0354\n",
      "Epoch 52/100\n",
      "78/78 [==============================] - 2s 21ms/step - loss: 0.0440 - root_mean_squared_error: 44019.2031 - mean_squared_logarithmic_error: 0.0440 - val_loss: 0.0350 - val_root_mean_squared_error: 49155.1172 - val_mean_squared_logarithmic_error: 0.0350\n",
      "Epoch 53/100\n",
      "78/78 [==============================] - 2s 20ms/step - loss: 0.0404 - root_mean_squared_error: 42755.8828 - mean_squared_logarithmic_error: 0.0404 - val_loss: 0.0348 - val_root_mean_squared_error: 49063.9180 - val_mean_squared_logarithmic_error: 0.0348\n",
      "Epoch 54/100\n",
      "78/78 [==============================] - 2s 20ms/step - loss: 0.0428 - root_mean_squared_error: 43873.2500 - mean_squared_logarithmic_error: 0.0428 - val_loss: 0.0345 - val_root_mean_squared_error: 48936.4297 - val_mean_squared_logarithmic_error: 0.0345\n",
      "Epoch 55/100\n",
      "78/78 [==============================] - 2s 20ms/step - loss: 0.0403 - root_mean_squared_error: 42417.5156 - mean_squared_logarithmic_error: 0.0403 - val_loss: 0.0344 - val_root_mean_squared_error: 48810.3398 - val_mean_squared_logarithmic_error: 0.0344\n",
      "Epoch 56/100\n",
      "78/78 [==============================] - 2s 20ms/step - loss: 0.0412 - root_mean_squared_error: 43363.0898 - mean_squared_logarithmic_error: 0.0412 - val_loss: 0.0341 - val_root_mean_squared_error: 48702.2969 - val_mean_squared_logarithmic_error: 0.0341\n",
      "Epoch 57/100\n",
      "78/78 [==============================] - 2s 20ms/step - loss: 0.0402 - root_mean_squared_error: 43718.9961 - mean_squared_logarithmic_error: 0.0402 - val_loss: 0.0338 - val_root_mean_squared_error: 48592.8477 - val_mean_squared_logarithmic_error: 0.0338\n",
      "Epoch 58/100\n",
      "78/78 [==============================] - 2s 20ms/step - loss: 0.0402 - root_mean_squared_error: 42427.2266 - mean_squared_logarithmic_error: 0.0402 - val_loss: 0.0336 - val_root_mean_squared_error: 48490.0898 - val_mean_squared_logarithmic_error: 0.0336\n",
      "Epoch 59/100\n",
      "78/78 [==============================] - 2s 20ms/step - loss: 0.0392 - root_mean_squared_error: 42090.9336 - mean_squared_logarithmic_error: 0.0392 - val_loss: 0.0333 - val_root_mean_squared_error: 48426.5430 - val_mean_squared_logarithmic_error: 0.0333\n",
      "Epoch 60/100\n",
      "78/78 [==============================] - 2s 20ms/step - loss: 0.0396 - root_mean_squared_error: 43210.8203 - mean_squared_logarithmic_error: 0.0396 - val_loss: 0.0330 - val_root_mean_squared_error: 48361.5820 - val_mean_squared_logarithmic_error: 0.0330\n",
      "Epoch 61/100\n",
      "78/78 [==============================] - 2s 20ms/step - loss: 0.0401 - root_mean_squared_error: 42984.9727 - mean_squared_logarithmic_error: 0.0401 - val_loss: 0.0329 - val_root_mean_squared_error: 48233.4531 - val_mean_squared_logarithmic_error: 0.0329\n",
      "Epoch 62/100\n",
      "78/78 [==============================] - 2s 20ms/step - loss: 0.0384 - root_mean_squared_error: 41603.0312 - mean_squared_logarithmic_error: 0.0384 - val_loss: 0.0325 - val_root_mean_squared_error: 48204.4570 - val_mean_squared_logarithmic_error: 0.0325\n",
      "Epoch 63/100\n",
      "78/78 [==============================] - 2s 20ms/step - loss: 0.0368 - root_mean_squared_error: 39535.1992 - mean_squared_logarithmic_error: 0.0368 - val_loss: 0.0323 - val_root_mean_squared_error: 48122.8828 - val_mean_squared_logarithmic_error: 0.0323\n",
      "Epoch 64/100\n",
      "78/78 [==============================] - 2s 21ms/step - loss: 0.0410 - root_mean_squared_error: 42744.1055 - mean_squared_logarithmic_error: 0.0410 - val_loss: 0.0322 - val_root_mean_squared_error: 48013.1133 - val_mean_squared_logarithmic_error: 0.0322\n",
      "Epoch 65/100\n",
      "78/78 [==============================] - 2s 20ms/step - loss: 0.0372 - root_mean_squared_error: 41248.8086 - mean_squared_logarithmic_error: 0.0372 - val_loss: 0.0319 - val_root_mean_squared_error: 47980.4805 - val_mean_squared_logarithmic_error: 0.0319\n",
      "Epoch 66/100\n",
      "78/78 [==============================] - 2s 20ms/step - loss: 0.0383 - root_mean_squared_error: 42024.9883 - mean_squared_logarithmic_error: 0.0383 - val_loss: 0.0318 - val_root_mean_squared_error: 47904.5781 - val_mean_squared_logarithmic_error: 0.0318\n",
      "Epoch 67/100\n",
      "78/78 [==============================] - 2s 20ms/step - loss: 0.0377 - root_mean_squared_error: 41484.0977 - mean_squared_logarithmic_error: 0.0377 - val_loss: 0.0316 - val_root_mean_squared_error: 47804.8008 - val_mean_squared_logarithmic_error: 0.0316\n",
      "Epoch 68/100\n",
      "78/78 [==============================] - 2s 20ms/step - loss: 0.0347 - root_mean_squared_error: 39320.9297 - mean_squared_logarithmic_error: 0.0347 - val_loss: 0.0314 - val_root_mean_squared_error: 47775.2109 - val_mean_squared_logarithmic_error: 0.0314\n",
      "Epoch 69/100\n",
      "78/78 [==============================] - 2s 21ms/step - loss: 0.0354 - root_mean_squared_error: 41063.2578 - mean_squared_logarithmic_error: 0.0354 - val_loss: 0.0313 - val_root_mean_squared_error: 47666.5781 - val_mean_squared_logarithmic_error: 0.0313\n",
      "Epoch 70/100\n",
      "78/78 [==============================] - 2s 20ms/step - loss: 0.0366 - root_mean_squared_error: 41171.2812 - mean_squared_logarithmic_error: 0.0366 - val_loss: 0.0311 - val_root_mean_squared_error: 47623.5391 - val_mean_squared_logarithmic_error: 0.0311\n",
      "Epoch 71/100\n",
      "78/78 [==============================] - 2s 20ms/step - loss: 0.0370 - root_mean_squared_error: 40793.0664 - mean_squared_logarithmic_error: 0.0370 - val_loss: 0.0310 - val_root_mean_squared_error: 47587.7578 - val_mean_squared_logarithmic_error: 0.0310\n",
      "Epoch 72/100\n",
      "78/78 [==============================] - 2s 20ms/step - loss: 0.0367 - root_mean_squared_error: 40520.7617 - mean_squared_logarithmic_error: 0.0367 - val_loss: 0.0308 - val_root_mean_squared_error: 47484.8203 - val_mean_squared_logarithmic_error: 0.0308\n",
      "Epoch 73/100\n",
      "78/78 [==============================] - 2s 20ms/step - loss: 0.0368 - root_mean_squared_error: 42099.4102 - mean_squared_logarithmic_error: 0.0368 - val_loss: 0.0308 - val_root_mean_squared_error: 47424.5430 - val_mean_squared_logarithmic_error: 0.0308\n",
      "Epoch 74/100\n",
      "78/78 [==============================] - 2s 21ms/step - loss: 0.0356 - root_mean_squared_error: 39856.8320 - mean_squared_logarithmic_error: 0.0356 - val_loss: 0.0306 - val_root_mean_squared_error: 47332.8359 - val_mean_squared_logarithmic_error: 0.0306\n",
      "Epoch 75/100\n",
      "78/78 [==============================] - 2s 21ms/step - loss: 0.0356 - root_mean_squared_error: 41121.4297 - mean_squared_logarithmic_error: 0.0356 - val_loss: 0.0305 - val_root_mean_squared_error: 47306.0586 - val_mean_squared_logarithmic_error: 0.0305\n",
      "Epoch 76/100\n",
      "78/78 [==============================] - 2s 20ms/step - loss: 0.0377 - root_mean_squared_error: 41736.4805 - mean_squared_logarithmic_error: 0.0377 - val_loss: 0.0303 - val_root_mean_squared_error: 47250.0469 - val_mean_squared_logarithmic_error: 0.0303\n",
      "Epoch 77/100\n",
      "78/78 [==============================] - 2s 20ms/step - loss: 0.0362 - root_mean_squared_error: 40350.9297 - mean_squared_logarithmic_error: 0.0362 - val_loss: 0.0301 - val_root_mean_squared_error: 47156.8125 - val_mean_squared_logarithmic_error: 0.0301\n",
      "Epoch 78/100\n",
      "78/78 [==============================] - 2s 20ms/step - loss: 0.0353 - root_mean_squared_error: 39489.8984 - mean_squared_logarithmic_error: 0.0353 - val_loss: 0.0300 - val_root_mean_squared_error: 47080.1758 - val_mean_squared_logarithmic_error: 0.0300\n",
      "Epoch 79/100\n",
      "78/78 [==============================] - 2s 21ms/step - loss: 0.0368 - root_mean_squared_error: 40893.1719 - mean_squared_logarithmic_error: 0.0368 - val_loss: 0.0298 - val_root_mean_squared_error: 47036.0352 - val_mean_squared_logarithmic_error: 0.0298\n",
      "Epoch 80/100\n",
      "78/78 [==============================] - 2s 20ms/step - loss: 0.0353 - root_mean_squared_error: 38916.4258 - mean_squared_logarithmic_error: 0.0353 - val_loss: 0.0297 - val_root_mean_squared_error: 46967.1250 - val_mean_squared_logarithmic_error: 0.0297\n",
      "Epoch 81/100\n",
      "78/78 [==============================] - 2s 20ms/step - loss: 0.0352 - root_mean_squared_error: 38533.1602 - mean_squared_logarithmic_error: 0.0352 - val_loss: 0.0295 - val_root_mean_squared_error: 46887.0078 - val_mean_squared_logarithmic_error: 0.0295\n",
      "Epoch 82/100\n",
      "78/78 [==============================] - 2s 20ms/step - loss: 0.0347 - root_mean_squared_error: 38259.3594 - mean_squared_logarithmic_error: 0.0347 - val_loss: 0.0294 - val_root_mean_squared_error: 46842.4531 - val_mean_squared_logarithmic_error: 0.0294\n",
      "Epoch 83/100\n",
      "78/78 [==============================] - 2s 20ms/step - loss: 0.0353 - root_mean_squared_error: 39040.2500 - mean_squared_logarithmic_error: 0.0353 - val_loss: 0.0294 - val_root_mean_squared_error: 46781.1680 - val_mean_squared_logarithmic_error: 0.0294\n",
      "Epoch 84/100\n",
      "78/78 [==============================] - 2s 21ms/step - loss: 0.0344 - root_mean_squared_error: 40212.0195 - mean_squared_logarithmic_error: 0.0344 - val_loss: 0.0295 - val_root_mean_squared_error: 46734.4805 - val_mean_squared_logarithmic_error: 0.0295\n",
      "Epoch 85/100\n",
      "78/78 [==============================] - 2s 20ms/step - loss: 0.0310 - root_mean_squared_error: 37017.9023 - mean_squared_logarithmic_error: 0.0310 - val_loss: 0.0292 - val_root_mean_squared_error: 46691.7109 - val_mean_squared_logarithmic_error: 0.0292\n",
      "Epoch 86/100\n",
      "78/78 [==============================] - 2s 21ms/step - loss: 0.0346 - root_mean_squared_error: 38374.2070 - mean_squared_logarithmic_error: 0.0346 - val_loss: 0.0291 - val_root_mean_squared_error: 46627.9023 - val_mean_squared_logarithmic_error: 0.0291\n",
      "Epoch 87/100\n",
      "78/78 [==============================] - 2s 20ms/step - loss: 0.0333 - root_mean_squared_error: 39346.9258 - mean_squared_logarithmic_error: 0.0333 - val_loss: 0.0291 - val_root_mean_squared_error: 46532.7461 - val_mean_squared_logarithmic_error: 0.0291\n",
      "Epoch 88/100\n",
      "78/78 [==============================] - 2s 20ms/step - loss: 0.0339 - root_mean_squared_error: 38932.6055 - mean_squared_logarithmic_error: 0.0339 - val_loss: 0.0290 - val_root_mean_squared_error: 46464.1055 - val_mean_squared_logarithmic_error: 0.0290\n",
      "Epoch 89/100\n",
      "78/78 [==============================] - 2s 21ms/step - loss: 0.0321 - root_mean_squared_error: 38552.5195 - mean_squared_logarithmic_error: 0.0321 - val_loss: 0.0286 - val_root_mean_squared_error: 46410.9805 - val_mean_squared_logarithmic_error: 0.0286\n",
      "Epoch 90/100\n",
      "78/78 [==============================] - 2s 20ms/step - loss: 0.0303 - root_mean_squared_error: 36828.2500 - mean_squared_logarithmic_error: 0.0303 - val_loss: 0.0285 - val_root_mean_squared_error: 46372.6250 - val_mean_squared_logarithmic_error: 0.0285\n",
      "Epoch 91/100\n",
      "78/78 [==============================] - 2s 20ms/step - loss: 0.0326 - root_mean_squared_error: 36784.3906 - mean_squared_logarithmic_error: 0.0326 - val_loss: 0.0284 - val_root_mean_squared_error: 46314.7891 - val_mean_squared_logarithmic_error: 0.0284\n",
      "Epoch 92/100\n",
      "78/78 [==============================] - 2s 20ms/step - loss: 0.0318 - root_mean_squared_error: 36815.9570 - mean_squared_logarithmic_error: 0.0318 - val_loss: 0.0283 - val_root_mean_squared_error: 46260.5195 - val_mean_squared_logarithmic_error: 0.0283\n",
      "Epoch 93/100\n",
      "78/78 [==============================] - 2s 20ms/step - loss: 0.0350 - root_mean_squared_error: 37828.7383 - mean_squared_logarithmic_error: 0.0350 - val_loss: 0.0282 - val_root_mean_squared_error: 46206.5430 - val_mean_squared_logarithmic_error: 0.0282\n",
      "Epoch 94/100\n",
      "78/78 [==============================] - 2s 20ms/step - loss: 0.0325 - root_mean_squared_error: 37629.5000 - mean_squared_logarithmic_error: 0.0325 - val_loss: 0.0282 - val_root_mean_squared_error: 46146.1133 - val_mean_squared_logarithmic_error: 0.0282\n",
      "Epoch 95/100\n",
      "78/78 [==============================] - 2s 20ms/step - loss: 0.0321 - root_mean_squared_error: 38346.9453 - mean_squared_logarithmic_error: 0.0321 - val_loss: 0.0282 - val_root_mean_squared_error: 46160.1797 - val_mean_squared_logarithmic_error: 0.0282\n",
      "Epoch 96/100\n",
      "78/78 [==============================] - 2s 20ms/step - loss: 0.0315 - root_mean_squared_error: 36841.3398 - mean_squared_logarithmic_error: 0.0315 - val_loss: 0.0282 - val_root_mean_squared_error: 46130.2383 - val_mean_squared_logarithmic_error: 0.0282\n",
      "Epoch 97/100\n",
      "78/78 [==============================] - 2s 20ms/step - loss: 0.0303 - root_mean_squared_error: 36347.4570 - mean_squared_logarithmic_error: 0.0303 - val_loss: 0.0280 - val_root_mean_squared_error: 46000.5469 - val_mean_squared_logarithmic_error: 0.0280\n",
      "Epoch 98/100\n",
      "78/78 [==============================] - 2s 20ms/step - loss: 0.0296 - root_mean_squared_error: 34763.7305 - mean_squared_logarithmic_error: 0.0296 - val_loss: 0.0278 - val_root_mean_squared_error: 45938.3750 - val_mean_squared_logarithmic_error: 0.0278\n",
      "Epoch 99/100\n",
      "78/78 [==============================] - 2s 20ms/step - loss: 0.0319 - root_mean_squared_error: 36217.1484 - mean_squared_logarithmic_error: 0.0319 - val_loss: 0.0277 - val_root_mean_squared_error: 45885.9727 - val_mean_squared_logarithmic_error: 0.0277\n",
      "Epoch 100/100\n",
      "78/78 [==============================] - 2s 20ms/step - loss: 0.0298 - root_mean_squared_error: 36315.4844 - mean_squared_logarithmic_error: 0.0298 - val_loss: 0.0280 - val_root_mean_squared_error: 45915.2148 - val_mean_squared_logarithmic_error: 0.0280\n"
     ]
    }
   ],
   "source": [
    "history2=house_price_model.fit(x=train_features_dict, y=train[label], epochs=100,batch_size=15,validation_split=split_fraction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make predictions and score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_and_visualize(model,x_test,y_test):\n",
    "    predictions=model.predict(x_test).flatten()\n",
    "    print(predictions.shape)\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.scatter(y_test,predictions)\n",
    "    plt.xlabel('True')\n",
    "    plt.ylabel('Predicted')\n",
    "    msle=mean_squared_log_error(y_true=y_test, y_pred=predictions)#msle is the metric evaluated in the kaggle challange\n",
    "    r2=r2_score(y_true=y_test, y_pred=predictions)\n",
    "    print('r2 coefficient: ',r2,'\\nmsle = ', msle)\n",
    "    z = np.polyfit(y_test, predictions, 1)\n",
    "    print(z)\n",
    "    p = np.poly1d(z)\n",
    "    plt.plot(y_test,p(y_test), color='magenta')\n",
    "    plt.axline((0,0),slope=1,ls='--')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'val_features_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\Users\\Alessandro\\Documents\\Machine Learning\\house-prices\\house-prices-tf.ipynb Cella 39\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Users/Alessandro/Documents/Machine%20Learning/house-prices/house-prices-tf.ipynb#X53sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m score_and_visualize(model\u001b[39m=\u001b[39mhouse_price_model,x_test\u001b[39m=\u001b[39mval_features_dict,y_test\u001b[39m=\u001b[39mval_df[label])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'val_features_dict' is not defined"
     ]
    }
   ],
   "source": [
    "score_and_visualize(model=house_price_model,x_test=val_features_dict,y_test=val_df[label])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "write=True\n",
    "\n",
    "test=pd.read_csv('test.csv')\n",
    "test=test[int_num_f]\n",
    "tf.convert_to_tensor(test)\n",
    "pred=model.predict(test)\n",
    "out_df=pd.read_csv('sample_submission.csv')\n",
    "out_df['SalePrice']=pred\n",
    "if write:\n",
    "    out_df.to_csv('prediction_tf.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=feat_eng(pd.read_csv('test.csv'))\n",
    "test[int_cat_f]=test[int_cat_f].fillna('none')\n",
    "test[int_num_f]=test[int_num_f].fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 1s 11ms/step\n"
     ]
    }
   ],
   "source": [
    "test_feature_dict={name:np.array(test[name]) for name in (int_num_f+int_cat_f)}\n",
    "for name in int_num_f:\n",
    "    test_feature_dict[name]=tf.cast(test_feature_dict[name],tf.float32)\n",
    "\n",
    "for name in int_cat_f:\n",
    "    test_feature_dict[name]=tf.cast(test_feature_dict[name],tf.string)\n",
    "\n",
    "pred=house_price_model.predict(test_feature_dict)\n",
    "out_df=pd.read_csv('sample_submission.csv')\n",
    "out_df['SalePrice']=pred\n",
    "if write:\n",
    "    out_df.to_csv('prediction_tf_allfeatures.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savemodel=False\n",
    "if savemodel:\n",
    "    timestamp=datetime.datetime.now().strftime(\"%d%m%Y%H%M%S\")\n",
    "    models_folder= 'models'\n",
    "    os.makedirs(models_folder,exist_ok=True)\n",
    "    model_name= 'model_'+ timestamp +'_tf.h5'\n",
    "    modelpath= os.path.join(models_folder,model_name)\n",
    "    model.save(modelpath)\n",
    "    print('Saved ' , modelpath)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('tfgpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4ac2639bf6c51b051b1b83c4d99575383d6e01bb4712884ebd29a7c900e61e25"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
